{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import gamma\n",
    "from scipy.special import gammaincc\n",
    "from scipy.integrate import dblquad\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.cm import get_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull(x, k, r):\n",
    "    # weibull distribution\n",
    "    first = k/x\n",
    "    second = (x*r*gamma(1 + k**(-1)))**k\n",
    "    third = np.exp(-(x*r*gamma(1+k**(-1)))**(k))\n",
    "\n",
    "    return first*second*third\n",
    "\n",
    "def weibull_ccdf(x, k, r):\n",
    "    # weibull complementary cumulative distribution function (1-cdf)\n",
    "    return np.exp(-(x*r*gamma(1 + k**(-1)))**k)\n",
    "\n",
    "def Nt_given_params(N, obs, times, k, r):\n",
    "    # likelihood of observing N bursts at times t1--tN given k and r\n",
    "    # obs: array like of observation lengths with bursts\n",
    "    # N: array like of number of bursts in each observation\n",
    "    # times: list of array like corresponding times of bursts in each observation\n",
    "\n",
    "    for i, ob_len in enumerate(obs):\n",
    "        time_array = times[i]\n",
    "        Ni = N[i]\n",
    "        term = r*weibull_ccdf(time_array[0], k, r)*weibull_ccdf(ob_len - time_array[-1], k, r)\n",
    "        if Ni==1:\n",
    "            return term\n",
    "        else:\n",
    "            for j, time in enumerate(time_array):\n",
    "\n",
    "                if j<=len(time_array) - 2:\n",
    "                    term *= weibull(time_array[j+1] - time_array[j], k, r)\n",
    "\n",
    "            return term\n",
    "\n",
    "def prior(k, r, dist='jeff'):\n",
    "    # prior distributions\n",
    "    if dist=='jeff':\n",
    "        return (k**(-1))*(r**(-1))\n",
    "    elif dist=='uni':\n",
    "        return 1\n",
    "\n",
    "def p_zerobursts(k, r, obsnb):\n",
    "    # probability of observing zero bursts\n",
    "    # needs obsnb array which is array of scan times with no bursts\n",
    "    def g(k, r, obs):\n",
    "        g = gamma(k**(-1))*gammaincc(k**(-1), (obs*r*gamma(1 + k**(-1)))**(k))/(k*gamma(1 + k**(-1))) \n",
    "        return g\n",
    "\n",
    "    for i, val in enumerate(tqdm(obsnb)):\n",
    "\n",
    "        if i==0:\n",
    "            tot = g(k, r, val)\n",
    "        else:\n",
    "            tot*=g(k, r, val)\n",
    "\n",
    "    return tot\n",
    "\n",
    "def posterior(k, r, obsnb, N, obsb, times, dist='jeff'):\n",
    "    if len(obsnb)==0:\n",
    "        return Nt_given_params(N, obsb, times, k, r)*prior(k, r, dist=dist)\n",
    "    else:\n",
    "\n",
    "        return Nt_given_params(N, obsb, times, k, r)*p_zerobursts(k, r, obsnb)*prior(k, r, dist=dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(infile):\n",
    "    # load dataframe\n",
    "    df = pd.read_pickle(infile)\n",
    "\n",
    "    # get Wb L-band observations while looking at SGR 1935\n",
    "    # L-band observations had 128 MHz bandwith, and P band had 64 MHz bandiwdth\n",
    "    df_wb_l = df[(df[\"Station\"] == \"wb\") & (df[\"Source\"] == \"SGR1935\") & (df[\"Bandwidth\"] == 128.0)]\n",
    "\n",
    "    #get dataframe corresponding to scans with no bursts\n",
    "    df_wb_l = df_wb_l[(df_wb_l[\"Code\"]!='sgrl21') | (df_wb_l[\"Scan\"]!=\"no0006\")]\n",
    "\n",
    "    #get onsala L-band scans\n",
    "    df_o_l = df[(df[\"Station\"] == \"o8\") & (df[\"Source\"] == \"SGR1935\")]\n",
    "\n",
    "    # get observation length of non-overlapping scans at Onsala\n",
    "    # so if scans overlap, omit the Onsala one\n",
    "    obs_len_o = []\n",
    "    for row in np.array(df_o_l[['MJD_start','MJD_end', 'Obslen_sec']]):\n",
    "        mjd_start = row[0]\n",
    "        mjd_end = row[1]\n",
    "        obs_len = row[2]\n",
    "        df_overlap = df_wb_l[((df_wb_l['MJD_start']>= mjd_start) & (df_wb_l['MJD_start']<= mjd_end))\n",
    "                            | ((df_wb_l['MJD_start']<=mjd_start) & (df_wb_l['MJD_end']>=mjd_start))]\n",
    "        if df_overlap.empty:\n",
    "             obs_len_o.append(obs_len)\n",
    "\n",
    "    obs_len_o = np.array(obs_len_o)\n",
    "    obs_len_wb = np.array(df_wb_l[\"Obslen_sec\"])\n",
    "\n",
    "    return np.concatenate((obs_len_o, obs_len_wb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2544/2544 [10:29<00:00,  4.04it/s]\n",
      "/home/m/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    # obs length with bursts (scan wbno0006, obsid sgrl21) in days\n",
    "    # if there are multiple scans with bursts, put each scan length \n",
    "    # as one entry in the list.\n",
    "    obs = [595.996736/86400]\n",
    "\n",
    "    # time of burst arrivals\n",
    "    # each entry corresponds to a list of arrival times (from beginning\n",
    "    # of observation) of bursts\n",
    "    times = [[246.059/86400, 247.455/86400]]\n",
    "\n",
    "    # num of bursts\n",
    "    # each entry corresponds to number of bursts in corresponding\n",
    "    # scan.\n",
    "    N = [2]\n",
    "\n",
    "    # grid to evaluate posterior on\n",
    "    kstart = 0.01\n",
    "    kstop = 2\n",
    "    rstart = -5 #-7\n",
    "    rstop = 5 #-1\n",
    "\n",
    "    # create k, r arrays\n",
    "    k = np.linspace(kstart, kstop, 1000)\n",
    "    r = np.logspace(rstart, rstop, 1000)\n",
    "\n",
    "    # want to evaluate in the middle of each bin\n",
    "    k_cent = 0.5*(k[1:] + k[:-1])\n",
    "    r_cent = 10**(0.5*(np.log10(r[1:]) + np.log10(r[:-1])))\n",
    "\n",
    "    # create meshgrid on centered values\n",
    "    km, rm = np.meshgrid(k_cent, r_cent)\n",
    "\n",
    "    # read in dataframe of observations.\n",
    "    # returns an array of scan lengths with\n",
    "    # no bursts\n",
    "    obslen_nb = read_df(\"campaign_dataframe.pkl\") / 86400 \n",
    "    \n",
    "    # calculate posterior ~ likelihood(scan with bursts)*likelihood(scans with no bursts)*prior \n",
    "    post = posterior(km, rm, obslen_nb, N, obs, times, dist='uni')\n",
    "\n",
    "    k_delta = k[1:] - k[:-1]\n",
    "    r_delta = r[1:] - r[:-1]\n",
    "\n",
    "    #create meshgrid of bin widths\n",
    "    kd_mesh, rd_mesh = np.meshgrid(k_delta, r_delta)\n",
    "\n",
    "    # use bin width meshgrid to normalize posterior\n",
    "    tot = np.sum(post*kd_mesh*rd_mesh)\n",
    "    post /= tot\n",
    "\n",
    "    # save normalized posterior as pickled data\n",
    "    np.save(\"wb_onsala_post\", [post, k, r], allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
